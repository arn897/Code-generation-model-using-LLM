# ğŸš€ Code Generation Model using LLM (Fine-Tuned CodeGen)

Transforming natural language into working Python code using a fine-tuned Large Language Model (LLM). This project showcases how you can build a code generator that accepts prompts like _"Write a binary search function"_ and returns clean, executable Python code. ğŸ§ ğŸ’»

---

## ğŸ“Œ Project Highlights

- ğŸ¤– Fine-tuned `Salesforce/codegen-350M-multi` using Hugging Face Transformers  
- ğŸ§‘â€ğŸ’» Generates Python functions from user-written prompts  
- âš¡ GPU-accelerated training and inference  
- ğŸ“¦ Works in notebooks or scripts for easy integration  
- ğŸ” Uses sampling methods like `top_k`, `top_p` for diverse generations  

---

## ğŸ“‚ Folder Structure

â”œâ”€â”€ data/ # Your dataset
â”œâ”€â”€ results/ # Checkpoints after training
â”œâ”€â”€ CodeGenLLM.ipynb # Training and inference notebook
â”œâ”€â”€ generate.py # Script to generate code from prompt
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

---

## ğŸ”§ Setup Instructions


# 1. Clone the repository
git clone https://github.com/arn897/Code-generation-model-using-llm.git
cd code-generation-llm

# 2. (Optional) Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# 3. Install dependencies
pip install -r requirements.txt


ğŸ’¡ How to Use
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

model_path = "./results/checkpoint-438"  # Path to saved model

tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(model_path).to("cuda")

def generate_code(prompt, max_length=300):
    inputs = tokenizer(prompt, return_tensors="pt").to("cuda")
    outputs = model.generate(
        **inputs,
        max_length=max_length,
        do_sample=True,
        temperature=0.7,
        top_k=50,
        top_p=0.95,
        pad_token_id=tokenizer.eos_token_id
    )
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# Example
print(generate_code("def quick_sort(arr):"))

ğŸ“Š Demo Output
Prompt:

python
Copy
Edit
def binary_search(arr, target):
Generated Output:

python
Copy
Edit
def binary_search(arr, target):
    left, right = 0, len(arr) - 1
    while left <= right:
        mid = (left + right) // 2
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            left = mid + 1
        else:
            right = mid - 1
    return -1

ğŸ§  Model Info

Base Model: Salesforce/codegen-350M-multi

Trained On: Custom prompts + Python code samples

Checkpoint Used: checkpoint-438

Framework: PyTorch + Hugging Face Transformers

ğŸ“Œ Technologies

Python ğŸ

Hugging Face ğŸ¤—

PyTorch ğŸ”¥

Jupyter Notebooks ğŸ““

CUDA (for GPU acceleration) ğŸ–¥ï¸


